{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Cancelación de Clientes (Churn)\n",
    "\n",
    "## Contexto\n",
    "El objetivo de este proyecto es predecir la cancelación de clientes de una empresa de telecomunicaciones a partir de datos históricos de comportamiento, servicios contratados y características del cliente.\n",
    "\n",
    "## Objetivo\n",
    "Construir y evaluar modelos de clasificación que permitan identificar clientes con alta probabilidad de cancelar el servicio, utilizando métricas apropiadas para problemas de clasificación desbalanceados.\n",
    "\n",
    "La evaluación del modelo se realizará utilizando ROC-AUC como métrica principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = pd.read_csv('/datasets/final_provider/contract.csv')\n",
    "personal = pd.read_csv('/datasets/final_provider/personal.csv')\n",
    "internet = pd.read_csv('/datasets/final_provider/internet.csv')\n",
    "phone = pd.read_csv('/datasets/final_provider/phone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de contrato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar información general sobre el dataset de contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos una función para convertir nombres de columnas a snake_case\n",
    "def to_snake_case(col_name):\n",
    "    # Separar palabras unidas por mayúsculas\n",
    "    col_name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', col_name)\n",
    "    # Manejar siglas o mayúsculas seguidas\n",
    "    col_name = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', col_name)\n",
    "    return col_name.lower()\n",
    "\n",
    "# creamos una función para limpiar un DataFrame completo\n",
    "def clean_dataframe(df):\n",
    "    # Convertir nombres de columnas\n",
    "    df = df.rename(columns=lambda x : to_snake_case(x))\n",
    "    # Limpiar espacios no deseados en las columnas tipo object\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos el dataframe\n",
    "contract = clean_dataframe(contract)\n",
    "\n",
    "# corregimos los tipos de datos\n",
    "    # begin_date y end_date deben ser datetime\n",
    "contract['begin_date'] = pd.to_datetime(contract['begin_date'], errors='coerce')\n",
    "contract['end_date'] = pd.to_datetime(contract['end_date'], errors='coerce')\n",
    "    # TotalCharges debe ser float64\n",
    "contract['total_charges'] = pd.to_numeric(contract['total_charges'], errors='coerce')\n",
    "# revisamos valores ausentes\n",
    "print('Valores ausentes', contract.isna().sum())\n",
    "# revisamos filas duplicadas\n",
    "print('Filas duplicadas', contract.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación:** Después de corregir los tipos de datos aparecieron valores ausentes en las columnas 'end_date' y 'total_charges', más adelante analizaremos a profundidad el significado de esto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos personales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar información general sobre el dataset de datos personales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos el dataframe\n",
    "personal = clean_dataframe(personal)\n",
    "\n",
    "# revisamos valores ausentes\n",
    "print('Valores ausentes:\\n', personal.isna().sum())\n",
    "# revisamos filas duplicadas\n",
    "print('\\nFilas duplicadas:\\n', personal.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan de internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar información general sobre el dataset del plan de internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos el dataframe\n",
    "internet = clean_dataframe(internet)\n",
    "\n",
    "# revisamos valores ausentes\n",
    "print('Valores ausentes:\\n', internet.isna().sum())\n",
    "# revisamos filas duplicadas\n",
    "print('\\nFilas duplicadas:\\n', internet.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan telefónico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar información general sobre el dataset del plan telefónico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpiar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos el dataframe\n",
    "phone = clean_dataframe(phone)\n",
    "\n",
    "# revisamos valores ausentes\n",
    "print('Valores ausentes:\\n', phone.isna().sum())\n",
    "# revisamos filas duplicadas\n",
    "print('\\nFilas duplicadas:\\n', phone.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unión de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unificamos las cuatro tablas de datos para poder hacer el análisis exploratorio\n",
    "df_merged = contract.merge(personal, on='customer_id', how='left')\n",
    "df_merged = df_merged.merge(internet, on='customer_id', how='left')\n",
    "full_data = df_merged.merge(phone, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que se hayan conservado correctamente todos los clientes después del merge\n",
    "print(full_data.shape)\n",
    "print()\n",
    "print(full_data['customer_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar información general sobre el dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "Existen 5174 valores ausentes en 'end_date', lo que significa que 5174 clientes aún tienen su contrato activo.\n",
    "\n",
    "Existen 1526 filas con valores ausentes en las columnas correspondientes al dataset internet, lo que significa que 1526 clientes no cuentan con el servicio de internet.\n",
    "\n",
    "Existen 682 filas con valores ausentes en la columna correspondiente al dataset phone, lo que significa que 682 clientes no cuentan con el servicio de telefonía.\n",
    "\n",
    "Lo anterior también nos indica que existen 2,208 clientes que poseen un solo servicio, y 4,835 clientes con ambos servicios contratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos los clientes que tienen valores ausentes en 'total_charges'\n",
    "full_data[full_data['total_charges'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación:**\n",
    "\n",
    "Las filas con valores ausentes en 'total_charges' se refieren a clientes que acaban de iniciar su contrato, por lo que aún no han acumulado ningún cargo total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratar valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos con 'No' los valores ausentes en las columnas correspondientes al dataset de internet\n",
    "internet_cols = ['internet_service', 'online_security', 'online_backup',\n",
    "                 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies']\n",
    "\n",
    "for col in internet_cols:\n",
    "    full_data[col] = full_data[col].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos\n",
    "print(full_data[internet_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos con 'No' los valores ausentes en la columna correspondiente al dataset de telefonía\n",
    "full_data['multiple_lines'] = full_data['multiple_lines'].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos\n",
    "print(full_data['multiple_lines'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos con 0 los valores ausentes en la columna 'total_charges'\n",
    "full_data['total_charges'] = full_data['total_charges'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos\n",
    "print(full_data['total_charges'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriquecer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una variable que indique si el cliente canceló su contrato (esta será nuestra nueva variable objetivo)\n",
    "full_data['churn'] = full_data['end_date'].notna().astype(int)\n",
    "\n",
    "# Agregar una variable para indicar la antigüedad del cliente\n",
    "reference_date = full_data['end_date'].max() # Usamos como referencia la última fecha observada en el dataset para evitar data leakage temporal\n",
    "full_data['end_date_filled'] = full_data['end_date'].fillna(reference_date)\n",
    "full_data['tenure'] = (\n",
    "    (full_data['end_date_filled'] - full_data['begin_date']).dt.days / 30\n",
    ").round()\n",
    "\n",
    "# Agregar una variable que indique si el cliente cuenta con el servivio de internet\n",
    "full_data['has_internet'] = (full_data['internet_service'] != 'No').astype(int)\n",
    "\n",
    "# Agregar una variable que indique si el cliente cuenta con el servicio de telefonía\n",
    "full_data['has_phone'] = (full_data['multiple_lines'] != 'No').astype(int)\n",
    "\n",
    "# Agregar una variable que indique si el cliente cuenta con un solo servicio\n",
    "full_data['one_service'] = (full_data['has_internet'] + full_data['has_phone'] == 1).astype(int)\n",
    "\n",
    "# Agregar el mes (por nombre y número) de inicio y fin de contrato\n",
    "full_data['begin_month'] = full_data['begin_date'].dt.month\n",
    "full_data['begin_month_name'] = full_data['begin_date'].dt.month_name()\n",
    "full_data['churn_month'] = full_data['end_date'].dt.month\n",
    "full_data['churn_month_name'] = full_data['end_date'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS GENERAL\n",
    "# Creamos un histograma para cada variable numérica\n",
    "full_data.hist(figsize=(12, 8), bins=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Creamos un boxplot para cada variable numérica (sin target)\n",
    "for col in full_data.select_dtypes(include='number'):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    sns.boxplot(x=full_data[col])\n",
    "    plt.title(f'Boxplot - {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Observamos la distribución de categorías en cada columna categórica\n",
    "for col in full_data.select_dtypes(include='object'):\n",
    "    print(f\"\\nDistribución de {col}:\")\n",
    "    print(full_data[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "Todas las variables numéricas muestran variabilidad suficiente, rangos adecuados y distribuciones coherentes en los histogramas y diagramas de caja. Ninguna presenta valores atípicos imposibles ni concentraciones extremas. Por lo tanto, todas son apropiadas para el análisis específico segmentado por el target.\n",
    "\n",
    "En cuanto a las variables categóricas, tras revisar las distribuciones con value_counts(), todas las variables presentaron variedad suficiente en sus categorías como para incluirlas en el análisis específico segmentado por el target. La única excepción es customer_id, ya que es un identificador único y no aporta información útil, por lo que se descartará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar columnas relevantes para análisis específico\n",
    "\n",
    "# Columnas que representan meses pero deben tratarse como categóricas\n",
    "meses_numericos = ['begin_month', 'churn_month']\n",
    "\n",
    "# Detectar columnas binarias numéricas (deben tratarse como categóricas)\n",
    "binarias_numericas = [\n",
    "    col for col in full_data.select_dtypes(include=['number']).columns\n",
    "    if full_data[col].nunique() == 2 and col != 'churn'\n",
    "]\n",
    "\n",
    "# Numéricas\n",
    "numericas_relevantes = [\n",
    "    col for col in full_data.select_dtypes(include=['number']).columns\n",
    "    if col not in ['churn'] + binarias_numericas + meses_numericos\n",
    "]\n",
    "\n",
    "# Categóricas\n",
    "categoricas_relevantes = [\n",
    "    col for col in full_data.select_dtypes(include=['object']).columns\n",
    "    if col not in ['customer_id']\n",
    "] + binarias_numericas\n",
    "\n",
    "# Orden natural de meses por nombre\n",
    "orden_meses_nombre = [\n",
    "    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "    \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos el balanceo de clases en la variable objetivo\n",
    "print(full_data['churn'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS ESPECÍFICO PARA VARIABLES NUMÉRICAS\n",
    "for col in numericas_relevantes:\n",
    "\n",
    "    # Creamos un boxplot segmentado por la variable objetivo\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.boxplot(x='churn', y=col, data=full_data)\n",
    "    plt.title(f'Boxplot segmentado por el target - {col}')\n",
    "    plt.show()\n",
    "\n",
    "    if (full_data[col].nunique() > 10):\n",
    "        # Creamos un KDE segmentado por la variable objetivo solo para variables continuas\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.kdeplot(data=full_data, x=col, hue='churn', common_norm=False)\n",
    "        plt.title(f'KDE segmentado por el target - {col}')\n",
    "        plt.show()\n",
    "\n",
    "    # Mostramos el valor medio de la columna según el target\n",
    "    print(f\"\\nValor medio de {col} según el target:\")\n",
    "    print(full_data.groupby('churn')[col].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "**Relación de los cargos mensuales con la cancelación del servicio:**\n",
    "\n",
    "Los clientes que cancelaron presentan cargos mensuales considerablemente más altos. El boxplot muestra que no hay valores anormales. El KDE confirma que los clientes activos se concentran en pagos entre 20 y 40 USD, mientras que quienes cancelaron se concentran principalmente entre 60 y 100 USD. Además, la media de pago mensual también es mayor en el grupo que se dio de baja (74 USD) en comparación con el grupo activo (61 USD). Esto sugiere que los clientes con tarifas más elevadas son más propensos a cancelar su contrato.\n",
    "\n",
    "**Relación de los cargos totales con la cancelación del servicio:**\n",
    "\n",
    "Los valores atípicos mostrados en el boxplot sugieren que solo una pequeña parte de los clientes que cancelaron su contrato llegaron a pagar más de 6000 USD totales.\n",
    "El KDE muestra que los clientes activos se concentran principalmente entre los 0 y 2500 USD totales, mientras que los que cancelaron se concentran entre los 0 y 1500 USD. \n",
    "Además, la media del pago total es mayor en el grupo que sigue activo (2549 USD) en comparación con el grupo que canceló su contrato (1531 USD).\n",
    "Esto tiene sentido ya que los clientes con contrato activo siguen acumulando cargos mientras que a los que ya cancelaron se les deja de cobrar.\n",
    "Con esto podemos concluir que la cancelación del servicio no se ve influenciada por los cargos totales, sino que los cargos totales reflejan la antigüedad.\n",
    "\n",
    "**Relación de la antigüedad con la cancelación del servicio:**\n",
    "\n",
    "Los valores atípicos en el boxplot sugieren que solo una pequeña parte de los clientes que cancelaron su servicio llevaba más de 70 meses de antigüedad.\n",
    "En el KDE los clientes activos muestran una distribución bastante uniforme entre los 0 y 80 meses de antigüedad, lo que indica una gran estabilidad. Por otro lado, los clientes que cancelaron se concentran mayormente entre los 0 y 20 meses.\n",
    "El valor medio de antigüedad es claramente mayor en los clientes activos (37 meses), en comparación con los clientes que cancelaron (18 meses).\n",
    "Todo lo anterior sugiere que existe una gran probabilidad de cancelación con clientes relativamente nuevos, mientras que con clientes antiguos la probabilidad es muy escasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS ESPECÍFICO PARA VARIABLES CATEGÓRICAS\n",
    "for col in categoricas_relevantes:\n",
    "    \n",
    "    plt.figure(figsize=(6,3))\n",
    "    # ordenar correctamente si la columna es de nombre de mes\n",
    "    if col in ['begin_month_name', 'churn_month_name']:\n",
    "        sns.barplot(x=col, y='churn', data=full_data, order=orden_meses_nombre)\n",
    "    else:\n",
    "        sns.barplot(x=col, y='churn', data=full_data)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Barplot - tasa de abandono por categoría de {col}')\n",
    "    plt.show()\n",
    "\n",
    "    # Mostramos el valor medio de abandono por categoría\n",
    "    print(f\"\\nTasa de abandono según {col}:\")\n",
    "    print(full_data.groupby(col)['churn'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "**Relación del tipo de contrato con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono varía de manera significativa según el tipo de contrato.\n",
    "Los clientes con contratos mensuales presentan la tasa de cancelación más alta (42%), mientras que quienes tienen contratos anuales y bienales muestran tasas mucho menores (11% y 2%, respectivamente). Esto podría deberse a que los contratos mensuales implican menos compromiso y permiten cancelar fácilmente, lo que los hace mucho más propensos a la deserción. En cambio, los contratos anuales y bienales suelen incluir beneficios, descuentos o penalizaciones por cancelación, lo que reduce drásticamente la probabilidad de cancelación.\n",
    "\n",
    "**Relación del tipo de facturación con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono para clientes con facturación electrónica (33%) es más del doble que la de clientes con facturación en papel (16%). Esto sugiere que quienes usan facturación electrónica tienden a cancelar con mayor frecuencia. Una explicación podría ser que este grupo de clientes suele ser más digital, mientras que los que utilizan facturación en papel podrían carecer de conocimiento tecnológico.\n",
    "\n",
    "**Relación del método de pago con la cancelación del servicio:**\n",
    "\n",
    "Los clientes que usan cheque electrónico presentan la tasa de cancelación más alta (45%), mientras que quienes utilizan cheques por correo, transferencia bancaria y tarjeta de crédito muestran tasas mucho menores y muy similares entre ellas (19%, 16% y 15%, respectivamente).\n",
    "Esto sugiere que existe una mayor probabilidad de cancelación entre los clientes que usan cheque electrónico. En cambio, los métodos automáticos y el pago por correo tienden a estar más asociados con clientes que permanecen activos.\n",
    "\n",
    "**Relación del género del cliente con la cancelación del servicio:**\n",
    "\n",
    "La tasa de cancelación es prácticamente igual entre hombres y mujeres (26.9% y 26.1%, respectivamente). Esta mínima diferencia no sugiere ningún patrón relevante, por lo que el género del cliente no parece influir en la probabilidad de cancelación del servicio.\n",
    "\n",
    "**Relación del estado de convivencia con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es más baja entre los clientes que viven con una pareja o compañero de hogar (19%) en comparación con quienes viven solos (32%). Esto sugiere que los clientes sin compañía son más propensos a cancelar su servicio. Una posible razón es que los hogares con más de una persona suelen compartir el servicio y dividir el costo, mientras que para quienes viven solos el gasto puede resultar más significativo.\n",
    "\n",
    "**Relación de los dependientes con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es considerablemente mayor entre los clientes que no tienen dependientes (31%) en comparación con quienes sí cuentan con ellos (15%). Esto sugiere que los clientes sin dependientes tienden a cancelar con más frecuencia, posiblemente porque no tienen otros miembros del hogar que dependan del servicio, lo que reduce su nivel de compromiso con mantenerlo activo.\n",
    "\n",
    "**Relación del tipo de servicio de internet con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es considerablemente mayor entre los clientes que cuentan con fibra óptica (41%), en comparación con quienes utilizan DSL (18%) o quienes no poseen servicio de internet (7%). Esto indica una fuerte asociación entre el uso de fibra óptica y una mayor probabilidad de cancelación, por lo que los clientes con este tipo de servicio resultan claramente más propensos a darse de baja.\n",
    "\n",
    "**Relación de la seguridad online con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es considerablemente mayor entre los clientes que no cuentan con seguridad online (31%) en comparación con quienes sí la tienen (14%). Esto sugiere que los usuarios sin este servicio adicional presentan una mayor tendencia a cancelar su contrato.\n",
    "\n",
    "**Relación de la copia de seguridad en la nube con la cancelación del servicio:**\n",
    "\n",
    "La tasa de cancelación es ligeramente mayor entre los clientes que no cuentan con copia de seguridad en la nube (29%), en comparación con quienes sí la tienen (21%). Esto sugiere que los usuarios sin este servicio adicional presentan una tendencia ligeramente mayor a cancelar su contrato.\n",
    "\n",
    "**Relación de la protección de dispositivo con la cancelación del servicio:**\n",
    "\n",
    "La tasa de cancelación es ligeramente mayor entre los clientes que no cuentan con protección de dispositivo (28%) en comparación con quienes sí la tienen (22%). Esto sugiere que los usuarios sin este servicio adicional presentan una tendencia un poco mayor a cancelar su contrato.\n",
    "\n",
    "**Relación del soporte técnico con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es considerablemente mayor entre los clientes que no cuentan con soporte técnico (31%) en comparación con quienes sí lo tienen (15%). Esto sugiere que los usuarios sin este servicio adicional presentan una mayor tendencia a cancelar su contrato.\n",
    "\n",
    "**Relación del streaming de TV con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es ligeramente mayor entre los clientes que cuentan con streaming de TV (30%) en comparación con los que no lo tienen (24%). Esto sugiere que los usuarios que cuentan con este servicio presentan una ligera mayor tendencia a cancelar su contrato.\n",
    "\n",
    "**Relación del streaming de películas con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es ligeramente mayor entre los clientes que cuentan con streaming de películas (29%) en comparación con quienes no lo tienen (24%). Esto sugiere que los usuarios que tienen este servicio adicional presentan una ligera tendencia mayor a cancelar su contrato.\n",
    "\n",
    "**Relación de la cantidad de líneas con la cancelación del servicio:**\n",
    "\n",
    "La tasa de cancelación para los clientes que cuentan con múltiples líneas y los que no son muy similares entre sí (28% y 25%, respectivamente). Esta mínima diferencia no sugiere ningún patrón relevante, por lo que la cantidad de líneas no parece influir en la probabilidad de cancelación del servicio.\n",
    "\n",
    "**Relación del mes de inicio del contrato con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono presenta variaciones importantes según el mes de inicio del contrato, con valores bajos a comienzos del año y un aumento progresivo hacia los últimos meses. Si bien el patrón es claro, los datos disponibles no permiten determinar la causa detrás de estas diferencias.\n",
    "\n",
    "**Relación del mes de cancelación con la tasa de abandono:**\n",
    "\n",
    "El mes de cancelación siempre presenta una tasa de abandono igual a 1, porque solo incluye casos donde el cliente abandonó. Por ello, esta variable no aporta información útil para el análisis de la cancelación.\n",
    "\n",
    "**Relación de la edad avanzada con la cancelación del servicio:**\n",
    "\n",
    "La tasa de abandono es considerablemente mayor entre los clientes de edad avanzada (41%) en comparación con quienes no lo son (23%). Esto indica que los adultos mayores muestran una mayor probabilidad de cancelar su contrato.\n",
    "\n",
    "**Relación de la tenencia del servicio de internet con la cancelación del servicio:**\n",
    "\n",
    "La tasa de cancelación es significativamente mayor entre los clientes que cuentan con servicio de internet (31%) en comparación con quienes no lo tienen (7%). Esto indica que los usuarios con servicio de internet presentan una probabilidad de cancelación mucho más alta que aquellos sin este servicio.\n",
    "\n",
    "**Relación de la tenencia del servicio telefónico con la cancelación del servicio:**\n",
    "\n",
    "La tasa de cancelación para los clientes que cuentan con servicio telefónico y para los que no lo tienen es bastante similar (28% y 25%, respectivamente). Esta diferencia mínima no sugiere ningún patrón relevante, por lo que el hecho de disponer o no del servicio telefónico no parece influir en la probabilidad de cancelación del contrato.\n",
    "\n",
    "**Relación de la tenencia de un solo servicio con la cancelación del contrato:**\n",
    "\n",
    "La tasa de abandono entre los clientes que cuentan con un solo servicio (29%) y quienes tienen ambos (25%) es muy similar. Esta diferencia mínima no revela un patrón significativo, por lo que el hecho de poseer uno o ambos servicios no parece influir de manera relevante en la probabilidad de cancelación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión del EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis exploratorio revela que la cancelación del servicio está asociada principalmente con tres dimensiones: el tipo de contrato del cliente, su antigüedad, y las características de los servicios que tiene contratados.\n",
    "\n",
    "En primer lugar, las variables relacionadas con el nivel de compromiso y la situación del hogar muestran patrones muy marcados: los clientes con contratos mensuales, que viven solos o que no tienen dependientes presentan tasas de abandono considerablemente más altas, mientras que quienes viven acompañados o tienen personas a su cargo tienden a mantener el servicio por más tiempo.\n",
    "\n",
    "En segundo lugar, la antigüedad del cliente (tenure) es uno de los factores más determinantes. La mayoría de las cancelaciones proviene de clientes relativamente nuevos, mientras que aquellos con muchos meses de permanencia casi no desertan. Esto indica que la retención temprana es clave: si un cliente supera los primeros meses, es mucho más probable que continúe usando el servicio.\n",
    "\n",
    "En cuanto a los servicios contratados, ciertos complementos como seguridad online, soporte técnico, copias de seguridad y protección de dispositivo están asociados con menores tasas de cancelación, lo que sugiere que los clientes que contratan servicios adicionales tienden a mantenerse activos por más tiempo. Por el contrario, los usuarios con fibra óptica y quienes utilizan métodos de pago como el cheque electrónico muestran una probabilidad significativamente mayor de cancelar.\n",
    "\n",
    "Finalmente, algunas variables como el género, cantidad de líneas telefónicas o tener uno vs. dos servicios, no muestran relación relevante con la cancelación de contrato. El mes de cancelación tampoco aporta información útil, mientras que el mes de inicio presenta variaciones claras pero sin una causa identificable con los datos disponibles.\n",
    "\n",
    "En conjunto, estos resultados permiten identificar perfiles de alto riesgo y factores asociados al abandono, lo cual será clave para el modelado predictivo y para el diseño de estrategias de retención."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear nuevas variables que aporten valor al modelado a partir del EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una variable que indique el número de servicios de protección adicionales\n",
    "full_data['num_protection_addons'] = (\n",
    "    full_data[['online_security','online_backup','device_protection','tech_support']]\n",
    "    .apply(lambda row: (row == 'Yes').sum(), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Durante el EDA se identificaron patrones claros asociados a clientes nuevos y a cargos altos.\n",
    "Se propusieron features binarias para capturar estos efectos, pero se descartaron por redundancia con tenure y monthly_charges, ya que los modelos utilizados pueden aprender estos umbrales directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deshacerse de las variables que conllevan fuga de datos o que no aportan nada al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = [\n",
    "    'customer_id',\n",
    "    'begin_date',\n",
    "    'end_date',\n",
    "    'begin_month_name',\n",
    "    'churn_month',\n",
    "    'churn_month_name',\n",
    "    'end_date_filled',\n",
    "    'one_service' # esta variable se creó anteriormente porque era útil para el EDA, pero para el modelado ya no es necesaria\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = full_data.drop(columns=drop_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir grupos de variables para el preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numéricas continuas\n",
    "num_features = ['monthly_charges', 'total_charges', 'tenure', 'num_protection_addons']\n",
    "\n",
    "# Binarias 0/1 (ya codificadas, se pasan tal cual al modelo)\n",
    "bin_features = [\n",
    "    'senior_citizen',\n",
    "    'has_internet',\n",
    "    'has_phone'\n",
    "]\n",
    "\n",
    "# Categóricas (incluye begin_month como categórica)\n",
    "cat_features = [\n",
    "    'type',\n",
    "    'paperless_billing',\n",
    "    'payment_method',\n",
    "    'gender',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'internet_service',\n",
    "    'online_security',\n",
    "    'online_backup',\n",
    "    'device_protection',\n",
    "    'tech_support',\n",
    "    'streaming_tv',\n",
    "    'streaming_movies',\n",
    "    'multiple_lines',\n",
    "    'begin_month'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir features y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = final_data.drop(columns=['churn'])\n",
    "target = final_data['churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir en conjuntos de entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_temp, features_test, target_temp, target_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features_temp, target_temp, test_size=0.25, random_state=42, stratify=target_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento (con y sin estandarización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un preprocesador sin escalado (árboles y boosting no lo necesitan)\n",
    "preprocess_no_scale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', num_features),\n",
    "        ('bin', 'passthrough', bin_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Creamos un preprocesador con StandardScaler (regresión logística y KNN lo necesitan)\n",
    "preprocess_scale = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('bin', 'passthrough', bin_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grupo A: Modelos clásicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un pipeline para cada modelo que automatiza todo el flujo de entrenamiento:\n",
    "# transforma los datos, balancea las clases y entrena el modelo en un solo proceso\n",
    "\n",
    "pipelines_A = {\n",
    "    'logistic': Pipeline([\n",
    "        ('preprocess', preprocess_scale),\n",
    "        ('model', LogisticRegression(max_iter=2000, class_weight='balanced'))\n",
    "    ]),\n",
    "    'tree': Pipeline([\n",
    "        ('preprocess', preprocess_no_scale),\n",
    "        ('model', DecisionTreeClassifier(random_state=42, class_weight='balanced'))\n",
    "    ]),\n",
    "    'rf': Pipeline([\n",
    "        ('preprocess', preprocess_no_scale),\n",
    "        ('model', RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced'))\n",
    "    ]),\n",
    "    'gb': Pipeline([\n",
    "        ('preprocess', preprocess_no_scale),\n",
    "        ('model', GradientBoostingClassifier(random_state=42))\n",
    "    ]),\n",
    "    'knn': Pipeline([\n",
    "        ('preprocess', preprocess_scale),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Definimos los hiperparámetros que GridSearchCV probará mediante validación cruzada, para seleccionar la mejor versión de cada modelo\n",
    "param_grids_A = {\n",
    "    'logistic': {'model__C': [0.1, 1, 10]},\n",
    "    'tree': {\n",
    "        'model__max_depth': [None, 5, 10, 20],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'rf': {\n",
    "        'model__n_estimators': [200, 500],\n",
    "        'model__max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'gb': {\n",
    "        'model__n_estimators': [100, 300],\n",
    "        'model__learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    'knn': {\n",
    "        'model__n_neighbors': [3, 5, 15],\n",
    "        'model__weights': ['uniform', 'distance']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Para cada modelo:\n",
    "# 1) Buscamos los mejores hiperparámetros usando validación cruzada solo en train\n",
    "# 2) Evaluamos el mejor modelo resultante en el conjunto de validación\n",
    "best_models_A = {}\n",
    "val_scores_A = {}\n",
    "\n",
    "print(\"=== Grupo A: CV en train, evaluación en valid ===\")\n",
    "\n",
    "for name in pipelines_A:\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipelines_A[name],\n",
    "        param_grid=param_grids_A[name],\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Aplicamos el pipeline completo sobre el conjunto de entrenamiento, utilizando validación cruzada para seleccionar los mejores hiperparámetros\n",
    "    grid.fit(features_train, target_train)\n",
    "    \n",
    "    # Guardamos el mejor pipeline encontrado para cada modelo\n",
    "    best_models_A[name] = grid.best_estimator_\n",
    "    \n",
    "    # Evaluamos el modelo en el conjunto de validación\n",
    "    proba_val = best_models_A[name].predict_proba(features_valid)[:, 1]\n",
    "    val_scores_A[name] = roc_auc_score(target_valid, proba_val)\n",
    "\n",
    "    print(f\"{name}: CV best={grid.best_score_:.4f} | valid={val_scores_A[name]:.4f} | params={grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grupo B: Modelos avanzados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Calculamos pesos para clases (negativos / positivos)\n",
    "n_neg = (target_train == 0).sum()\n",
    "n_pos = (target_train == 1).sum()\n",
    "\n",
    "# Para XGBoost: ratio neg/pos\n",
    "scale_pos_weight = n_neg / n_pos\n",
    "\n",
    "# Para CatBoost: [peso_clase_0, peso_clase_1]\n",
    "# (hacemos que la clase positiva pese más)\n",
    "class_weights_cb = [1.0, scale_pos_weight]\n",
    "\n",
    "# 2) Preprocesamos (fit solo en train)\n",
    "preprocess_no_scale.fit(features_train)\n",
    "\n",
    "features_train_proc = preprocess_no_scale.transform(features_train)\n",
    "features_valid_proc = preprocess_no_scale.transform(features_valid)\n",
    "\n",
    "\n",
    "# Para cada modelo:\n",
    "# A diferencia del Grupo A, aquí no hacemos una búsqueda de los mejores hiperparámetros. En su lugar, monitoreamos el desempeño en validación durante el entrenamiento para controlar el sobreajuste.\n",
    "# Estos modelos se entrenan con configuraciones sólidas por defecto y ajuste ligero.\n",
    "val_scores_B = {}\n",
    "\n",
    "print(\"\\n=== Grupo B: monitoreo de desempeño y evaluación con valid ===\")\n",
    "\n",
    "# ------- Creamos XGBoost -------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='auc',\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "# Entrenamos XGBoost y utilizamos el conjunto de validación para monitorear el desempeño y aplicar early stopping\n",
    "xgb_model.fit(\n",
    "    features_train_proc, target_train,\n",
    "    eval_set=[(features_valid_proc, target_valid)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "proba_val = xgb_model.predict_proba(features_valid_proc)[:, 1]\n",
    "val_scores_B['xgb'] = roc_auc_score(target_valid, proba_val)\n",
    "\n",
    "\n",
    "# ------- Creamos LightGBM -------\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "# Entrenamos LightGBM y utilizamos el conjunto de validación para monitorear el desempeño y aplicar early stopping\n",
    "lgbm_model.fit(\n",
    "    features_train_proc, target_train,\n",
    "    eval_set=[(features_valid_proc, target_valid)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    ")\n",
    "\n",
    "proba_val = lgbm_model.predict_proba(features_valid_proc)[:, 1]\n",
    "val_scores_B['lgbm'] = roc_auc_score(target_valid, proba_val)\n",
    "\n",
    "\n",
    "# ------- Creamos CatBoost -------\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=3000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    random_seed=42,\n",
    "    verbose=0,\n",
    "    eval_metric='AUC',\n",
    "    class_weights=class_weights_cb,\n",
    "    od_type='Iter',\n",
    "    od_wait=50\n",
    ")\n",
    "# Entrenamos CatBoost y utilizamos el conjunto de validación para monitorear el desempeño y aplicar early stopping\n",
    "cat_model.fit(\n",
    "    features_train_proc, target_train,\n",
    "    eval_set=(features_valid_proc, target_valid),\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "proba_val = cat_model.predict_proba(features_valid_proc)[:, 1]\n",
    "val_scores_B['catboost'] = roc_auc_score(target_valid, proba_val)\n",
    "\n",
    "# Mostramos las puntuaciones\n",
    "print(val_scores_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los modelos de mejor a peor según su AUC-ROC en validación\n",
    "final_val_scores = {**val_scores_A, **val_scores_B}\n",
    "ranking = sorted(final_val_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Mostramos los modelos y su puntuación\n",
    "print(\"\\n=== Ranking de modelos según AUC-ROC en validación ===\")\n",
    "for name, score in ranking:\n",
    "    print(name, round(score, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación final del mejor modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Elegimos el mejor modelo según el ranking en validación\n",
    "best_model_name, best_val_score = ranking[0]\n",
    "print(f\"\\nMejor modelo según validación: {best_model_name} (AUC={best_val_score:.4f})\")\n",
    "\n",
    "# 2. Entrenamos el mejor modelo en train+valid\n",
    "features_train_full = pd.concat([features_train, features_valid])\n",
    "target_train_full = pd.concat([target_train, target_valid])\n",
    "\n",
    "\n",
    "if best_model_name in best_models_A:\n",
    "    # -------------------------------\n",
    "    # Modelos del grupo A (pipelines)\n",
    "    # -------------------------------\n",
    "    best_model = best_models_A[best_model_name]\n",
    "\n",
    "    # Reentrenamos el pipeline completo desde cero con train+valid\n",
    "    best_model.fit(features_train_full, target_train_full)\n",
    "\n",
    "    # Predicción en test\n",
    "    proba_test = best_model.predict_proba(features_test)[:, 1]\n",
    "\n",
    "else:\n",
    "    # -------------------------------\n",
    "    # Modelos del grupo B (boosting)\n",
    "    # -------------------------------\n",
    "    # Preprocesamiento\n",
    "    preprocess_no_scale.fit(features_train_full)\n",
    "    features_train_full_proc = preprocess_no_scale.transform(features_train_full)\n",
    "    features_test_proc = preprocess_no_scale.transform(features_test)\n",
    "\n",
    "    # Re-creamos el modelo según el nombre\n",
    "    if best_model_name == 'xgb':\n",
    "        final_model = XGBClassifier(\n",
    "            n_estimators=3000,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            eval_metric='auc',\n",
    "            scale_pos_weight=scale_pos_weight\n",
    "        )\n",
    "    elif best_model_name == 'lgbm':\n",
    "        final_model = LGBMClassifier(\n",
    "            n_estimators=3000,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "    elif best_model_name == 'catboost':\n",
    "        final_model = CatBoostClassifier(\n",
    "            iterations=3000,\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            random_seed=42,\n",
    "            verbose=0,\n",
    "            eval_metric='AUC',\n",
    "            class_weights=class_weights_cb\n",
    "        )\n",
    "\n",
    "    # Entrenamos el modelo final\n",
    "    final_model.fit(features_train_full_proc, target_train_full)\n",
    "\n",
    "    # Predicción en test\n",
    "    proba_test = final_model.predict_proba(features_test_proc)[:, 1]\n",
    "\n",
    "\n",
    "# 3. Calculamos AUC-ROC en test\n",
    "test_auc = roc_auc_score(target_test, proba_test)\n",
    "\n",
    "print(f\"\\nAUC-ROC final en TEST: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estrategia de evaluación de modelos**\n",
    "\n",
    "Para la selección del modelo predictivo se implementó una estrategia de evaluación en dos niveles. En primer lugar, para los modelos de menor costo computacional (Logistic Regression, KNN, Decision Tree, Random Forest y Gradient Boosting de scikit-learn), se utilizó validación cruzada mediante GridSearchCV con el objetivo de optimizar hiperparámetros, aplicándose únicamente sobre el conjunto de entrenamiento. Este proceso permitió obtener, para cada modelo, una configuración optimizada sin utilizar información del conjunto de validación.\n",
    "\n",
    "Posteriormente, los modelos ya optimizados se evaluaron sobre un conjunto de validación independiente para compararlos entre sí utilizando la métrica ROC-AUC. Para modelos más complejos como XGBoost, LightGBM y CatBoost, no se empleó validación cruzada exhaustiva debido a su mayor costo computacional; en su lugar, se usaron configuraciones iniciales bien establecidas y early stopping para controlar el sobreajuste. Finalmente, el modelo seleccionado se evaluó una sola vez sobre el conjunto de prueba, garantizando una comparación justa y evitando fuga de información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto se desarrolló un modelo predictivo para estimar la probabilidad de cancelación de clientes del operador de telecomunicaciones Interconnect, utilizando información contractual, personal y de servicios contratados. El problema se abordó como una tarea de clasificación binaria, donde el objetivo fue identificar si un cliente cancela o no su contrato.\n",
    "\n",
    "A partir del análisis exploratorio de datos, se identificaron patrones claros asociados a la cancelación del servicio. Los clientes con contratos mensuales, menor antigüedad, cargos mensuales elevados y menos servicios adicionales presentan una probabilidad significativamente mayor de cancelar. Asimismo, variables relacionadas con el contexto del hogar, como no vivir con una pareja o no tener dependientes, también se asociaron con mayores tasas de abandono. Por el contrario, clientes con mayor antigüedad y con servicios adicionales como soporte técnico o seguridad online muestran una mayor permanencia.\n",
    "\n",
    "Para el modelado predictivo se evaluaron distintos algoritmos de clasificación, incluyendo modelos lineales, modelos basados en árboles y técnicas de boosting. La selección del modelo se realizó utilizando la métrica ROC-AUC sobre un conjunto de validación independiente. El modelo con mejor desempeño fue CatBoost, que alcanzó un AUC-ROC de 0.939 en el conjunto de prueba, lo que indica una alta capacidad para diferenciar entre clientes que cancelan y clientes que permanecen activos.\n",
    "\n",
    "Este resultado indica que el modelo puede utilizarse como una herramienta de apoyo para identificar clientes con mayor probabilidad de cancelar su contrato. En particular, permite detectar clientes en riesgo con anticipación, lo que podría ayudar a la empresa a tomar acciones de retención a tiempo.\n",
    "\n",
    "Desde el punto de vista del negocio, el modelo podría servir para priorizar clientes a los que se les puedan ofrecer promociones, descuentos o servicios adicionales, especialmente en el caso de clientes nuevos o con contratos mensuales.\n",
    "\n",
    "Como limitación, el modelo se basa únicamente en la información disponible en los datos proporcionados y no considera otros factores que podrían influir en la cancelación. Además, no se define un umbral específico para la toma de decisiones, por lo que este debería ajustarse según los objetivos del negocio.\n",
    "\n",
    "En conclusión, el proyecto demuestra que es posible predecir la cancelación de clientes utilizando los datos disponibles y que estos resultados pueden servir como apoyo para futuras estrategias de retención en Interconnect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
